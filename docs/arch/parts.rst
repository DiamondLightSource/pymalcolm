Blocks and Parts
================

Blocks, Methods, and Attributes are what is exposed by Malcolm at run-time.
However, during the first iteration of Malcolm, it became apparent that
Python classes that implemented Blocks were too large and unweildy to easily
share code. Likewise, Attributes and Methods were too small, what is needed is
a collection of a small number of Attributes and Methods that form a coherent
reusable group. We will call these `Parts`. Blocks will be formed as a
composition of Parts, and to avoid repeating ourselves, we will define a
configuration language written in YAML.

A Block would be created by parsing a YAML file for initialisation Attributes,
taking values for those, and creating an object composed of the component parts.
Different component parts will typically be used depending on the function of
the block. There are 3 levels in the heirarchy of blocks, plus a 4th category
of blocks in the Hardware interface layer:

.. uml::
    !include docs/style.iuml

    frame "Supervisory" {
        [GDA CPU scan]
        [Spiral scan]
    }

    frame "Logical Devices" {
        [Detector]
        [Zebra2]
        [Motor]
    }
    [GDA CPU scan] - [Detector]
    [Spiral scan] - [Detector]
    [Spiral scan] - [Zebra2]
    [Spiral scan] - [Motor]

    frame "Hardware interface" {
        component "Detector manager" {
            [Detector\ndriver] -right-> [Position\nplugin]
            [Position\nplugin] -right-> [HDF\nwriter]
        }
        [Detector] - [Detector\ndriver]
        [Detector] - [Position\nplugin]
        [Detector] - [HDF\nwriter]

        component "Zebra2 manager" {
            [PCOMP] -right-> [PCAP]
        }
        [Zebra2] - [PCOMP]
        [Zebra2] - [PCAP]

        [Traj]
        [Motor] - [Traj]
    }

The interface is best described by providing an example of a Block in each
layer.

Hardware interface
------------------

Blocks in this level have only the default statemachine. They have no
configuration function, just attributes that map directly to the underlying PVs
or hardware attributes. They are generated by the module owner and also serve
as documentation as to which PVs are externally important.

.. highlight:: yaml

This is a detector driver block::

    # define initialisation attributes
    init.String:
        name: prefix
        description: PV Prefix
        required: true

    # top level groups of parameters
    gui.Group:
        name: configuration
        label: Configuration Parameters
        description: These will be used to configure the device

    # a PV Attribute, one that connects to a demand and readback PV
    ca.Double:
        name: exposure
        description: Exposure time for each frame
        pv: {prefix}:Exposure
        rbv_suff: _RBV
        widget: textinput
        group: configuration

    ca.LongString:
        name: xml
        description: XML describing positions to tag NDArrays with
        pv: {prefix}:Filename
        widget: textarea
        group: configuration
        writeable: true

    ca.Enum:
        name: acquire
        description: Whether it is acquiring or not
        pv: {prefix}:Acquire
        labels:
            - Idle
            - Acquire
        widget: toggle
        writeable: true

This has then defined the PV interface for a particular template, and nothing
else. The default stateMachine is included, but no methods are created, and the
attributes map directly onto PVs. The writeable PVs have a put method.

All of these will call ca.create_pv(), monitor the resulting PV, and keep a
local attribute in sync with this value. If writeable, it will create a setter
on the attribute that does a caput callback on the PV, doing a get on the RBV
value to avoid the race condition on return.

Configuration Managers
----------------------

Blocks in the `Hardware interface`_ expose a very thin layer over the underlying
hardware. They are typically multipurpose blocks that could be combined in a
number of ways. Configuration Manager Blocks are responsible for the connections
between a number of hardware blocks, loading and saving configurations for them,
and marking them as active or inactive. Zebra2 web gui will communicate with one
of these managers, but the same principle and gui can be applied to areaDetector
plugin chains. Each load or save creates a `Logical Devices`_ Block, with the
fixed attributes coming from the current values, and the mirrored and slaved
attributes being specified in two tables:

======= =============== ====================
Mirrors
--------------------------------------------
Name    Source          Description
======= =============== ====================
Arm     PCAP.START      Start the experiment
Start   PCOMP1.START
======= =============== ====================

=============== ======
Slaves
----------------------
Name            Source
=============== ======
PCOMP2.START    Start
=============== ======

**********how to fix block child names for position plugin?


Logical Devices
---------------

These are parent blocks that summarize a number of child blocks in the
CA/hardware interface layer. They contain a mapping of configuration parameters
to the underlying blocks, and generally have the
:ref:`runnable-device-state-machine`. They can be generated by a block in the
`Configuration Managers`_ layer, or manually. They fix the setup of a particular
group of blocks, and expose a small number of user configurable parameters to
the higher level. They do this by identifying each of the writeable attributes
of the child device as one of the following 3 categories:

- fixed: during reset, the value of the child attribute is set. If it is changed
  by someone other than the parent device, the parent device goes into Fault
  state.

  For example::

    # set positionPlugin.enabled=1 on reset
    fixed.positionPlugin.enabled:
        value: 1

  Tables can be represented as repeated key value pairs::

    fixed.detectorDriver2.positions:
        value:
            - x: 32
              y: 45
            - x: 33
              y: 46

- mirror: this creates a parent attribute that is a mirror of the child
  attribute. If the child attribute is changed, the mirror changes, and if the
  child attribute is writeable then writes to the parent attribute will
  propagate to the child attribute. If the child attribute is writeable it will
  also add it to a list of configurable fields.

  For example::

    # Create self.exposure deferring puts to detectorDriver.exposure
    mirror.detectorDriver.exposure:
        name: exposure

- slave: this slaves a child attribute to an existing parent attribute. If the
  parent attribute is changed then the child attribute will be set to the same
  value. If the child attribute changes then the parent device goes into Fault
  state.

  For example::

    # set detectorDriver2 exposure whenever self.exposure changes
    slave.detectorDriver2.exposure:
        source: exposure

However, this doesn't address how to implement a configure/run statemachine on
top of these attributes. For this we need to instantiate the base statemachine
that will allow the various states::

    sm.AreaDetectorRunnableDevice:

This will provide all the configure/run/pause/retrace methods, and a number of
hooks that Parts can hook into. For instance, the mirrored attributes use this
hook to allow setting of that attribute during configure. As well as a hook for
each state, the AreaDetectorRunnableDevice statemachine will define substate
hooks for specific operations, so for the running states we have hooks for:

- PreRunPluginStart
- PreRunDriverStart
- Running
- PostRun

.. highlight:: python

These hooks can be used to make sure that configure and run operations are
sequenced in the correct order. The hooked functions will be run concurrently
in each phase, and the phase won't advance until they have all completed. For
example, a position plugin might look like this::

    from malcolm.sm import AreaDetectorRunnableDevice


    class PosPart(Part):

        @AreaDetectorRunnableDevice.Configure
        def configure(self, task, device):
            pos = device.positionPlugin
            # start some puts off in the background
            future = task.put_async({
                pos.delete: True,
                pos.idStart: 1,
                pos.enableCallbacks: True})
            # calculate the first 100 positions
            xml = self._generate_xml(0, 100)
            # wait until puts are done
            task.wait_all(future)
            # put the first 100 points
            task.put(pos.xml, xml)
            self._loaded = 100

        def _load_pos(self, positions):
            if positions < 100 and self._loaded < self.device.totalSteps:
                # add up to 100 more positions
                num = min(100, self.device.totalSteps - self._loaded)
                xml = self._generate_xml(self._loaded, num)
                self.device.pos.xml.put(xml)
                self._loaded += num

        @AreaDetectorRunnableDevice.PreRunPluginStart
        def start_plugin(self, task, device):
            pos = device.positionPlugin
            # Each time the number of positions left changes, call a function
            # to load positions if we're getting low
            # This will live for as long as the self.load_f future does
            self.load_f = task.listen(pos.positions, self._load_pos)
            # Start us off running
            running_f = task.when_matches(pos.running, True)
            self.done_f = task.put_async(device.pos.start, True)
            task.wait_all(running_f)

        @AreaDetectorRunnableDevice.Running
        def running(self, task, device):
            task.wait_all(self.done_f)
            self.load_f.cancel()

.. highlight:: yaml

This would be instantiated by::

    parts.PosPart:

Supervisory
-----------

These are the highest level entry point, and will typically be used directly
from GDA. They will have the RunnableDevice statemachine. They will adapt to
the detectors and motors that they are given at configuration, and do a
complete mapping scan by controlling `Logical Devices`_. We can specify the
child blocks at init::

    init.DetectorsArray:
        name: detectors
        description: Detector instances to be triggered
        required: true
        trackError: true


